{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the mp_setup.sh bash file (I wasnt sure if we wanted to keep using a notebook)\n",
    "# Will install mediapipe to the global env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown To better demonstrate the Pose Landmarker API, we have created a set of visualization tools that will be used in this colab. These will draw the landmarks on a detect person, as well as the expected connections between those markers.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cv2_imshow(image):\n",
    "    \"\"\"\n",
    "    Display an image using matplotlib in Jupyter Notebook.\n",
    "\n",
    "    Args:\n",
    "        image: The image to display. Should be in BGR format (OpenCV default).\n",
    "    \"\"\"\n",
    "    # Convert the image from BGR (OpenCV default) to RGB (matplotlib default)\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "girl_img = cv2.imread(\"sample-frames/mp_example.png\")\n",
    "cv2_imshow(girl_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Media Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "def mp_init_detector(model_path='mp-model/pose_landmarker.task'):\n",
    "    # STEP 2: Create a PoseLandmarker object.\n",
    "    base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        output_segmentation_masks=True)\n",
    "    return vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "def mp_process_image(detector, mp_img):\n",
    "    # Detect features in image\n",
    "    detection_result = detector.detect(mp_img)\n",
    "\n",
    "    # Associate enums with string values\n",
    "    body_parts_dict = {\n",
    "        'nose': mp.solutions.pose.PoseLandmark.NOSE,\n",
    "        'left_eye_inner': mp.solutions.pose.PoseLandmark.LEFT_EYE_INNER,\n",
    "        'left_eye': mp.solutions.pose.PoseLandmark.LEFT_EYE,\n",
    "        'left_eye_outer': mp.solutions.pose.PoseLandmark.LEFT_EYE_OUTER,\n",
    "        'right_eye_inner': mp.solutions.pose.PoseLandmark.RIGHT_EYE_INNER,\n",
    "        'right_eye': mp.solutions.pose.PoseLandmark.RIGHT_EYE,\n",
    "        'right_eye_outer': mp.solutions.pose.PoseLandmark.RIGHT_EYE_OUTER,\n",
    "        'left_ear': mp.solutions.pose.PoseLandmark.LEFT_EAR,\n",
    "        'right_ear': mp.solutions.pose.PoseLandmark.RIGHT_EAR,\n",
    "        'mouth_left': mp.solutions.pose.PoseLandmark.MOUTH_LEFT,\n",
    "        'mouth_right': mp.solutions.pose.PoseLandmark.MOUTH_RIGHT,\n",
    "        'left_shoulder': mp.solutions.pose.PoseLandmark.LEFT_SHOULDER,\n",
    "        'right_shoulder': mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER,\n",
    "        'left_elbow': mp.solutions.pose.PoseLandmark.LEFT_ELBOW,\n",
    "        'right_elbow': mp.solutions.pose.PoseLandmark.RIGHT_ELBOW,\n",
    "        'left_wrist': mp.solutions.pose.PoseLandmark.LEFT_WRIST,\n",
    "        'right_wrist': mp.solutions.pose.PoseLandmark.RIGHT_WRIST,\n",
    "        'left_pinky': mp.solutions.pose.PoseLandmark.LEFT_PINKY,\n",
    "        'right_pinky': mp.solutions.pose.PoseLandmark.RIGHT_PINKY,\n",
    "        'left_index': mp.solutions.pose.PoseLandmark.LEFT_INDEX,\n",
    "        'right_index': mp.solutions.pose.PoseLandmark.RIGHT_INDEX,\n",
    "        'left_thumb': mp.solutions.pose.PoseLandmark.LEFT_THUMB,\n",
    "        'right_thumb': mp.solutions.pose.PoseLandmark.RIGHT_THUMB,\n",
    "        'left_hip': mp.solutions.pose.PoseLandmark.LEFT_HIP,\n",
    "        'right_hip': mp.solutions.pose.PoseLandmark.RIGHT_HIP,\n",
    "        'left_knee': mp.solutions.pose.PoseLandmark.LEFT_KNEE,\n",
    "        'right_knee': mp.solutions.pose.PoseLandmark.RIGHT_KNEE,\n",
    "        'left_ankle': mp.solutions.pose.PoseLandmark.LEFT_ANKLE,\n",
    "        'right_ankle': mp.solutions.pose.PoseLandmark.RIGHT_ANKLE,\n",
    "        'left_heel': mp.solutions.pose.PoseLandmark.LEFT_HEEL,\n",
    "        'right_heel': mp.solutions.pose.PoseLandmark.RIGHT_HEEL,\n",
    "        'left_foot_index': mp.solutions.pose.PoseLandmark.LEFT_FOOT_INDEX,\n",
    "        'right_foot_index': mp.solutions.pose.PoseLandmark.RIGHT_FOOT_INDEX\n",
    "    }\n",
    "\n",
    "    # Create a dictonary so we can index into body parts\n",
    "    # EX Usage: body_parts['ankle_left]\n",
    "    body_parts = {}\n",
    "    if detection_result.pose_landmarks:\n",
    "        for pose_landmarks in detection_result.pose_landmarks:\n",
    "            for part_name, part_enum in body_parts_dict.items():\n",
    "                body_parts[part_name] = pose_landmarks[part_enum]\n",
    "\n",
    "    return detection_result, body_parts\n",
    "\n",
    "def mp_debug_show_image(detector, img_path):\n",
    "    image = mp.Image.create_from_file(img_path)\n",
    "\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at path {img_path} could not be loaded.\")\n",
    "\n",
    "    detection_result, _ = mp_process_image(detector, image)\n",
    "\n",
    "    image_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # STEP 5: Process the detection result. In this case, visualize it.\n",
    "    annotated_image = draw_landmarks_on_image(\n",
    "        image_rgb,\n",
    "        detection_result\n",
    "    )\n",
    "\n",
    "    # Display the annotated image, otherwise return it.\n",
    "    cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "mp_detector = mp_init_detector()\n",
    "mp_image = mp.Image.create_from_file(\"sample-frames/mp_example.png\")\n",
    "detection_results, body_parts = mp_process_image(\n",
    "    mp_detector,\n",
    "    mp_image\n",
    ")\n",
    "\n",
    "left_food_index = body_parts['left_foot_index']\n",
    "print(\"Left foot index\")\n",
    "print(f\"position: {left_food_index.x:.3f}, {left_food_index.y:.3f}, {left_food_index.z:.3f}\")\n",
    "print(f\"visibility: {left_food_index.visibility:.3f}\")\n",
    "\n",
    "# Debug\n",
    "mp_debug_show_image(mp_detector,\"sample-frames/mp_example.png\")\n",
    "mp_debug_show_image(mp_detector,\"sample-frames/good1.png\")\n",
    "mp_debug_show_image(mp_detector,\"sample-frames/good2.png\")\n",
    "\n",
    "mp_debug_show_image(mp_detector,\"sample-frames/bad1.png\")\n",
    "mp_debug_show_image(mp_detector,\"sample-frames/bad2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c, img_rgb=None, color=(255, 0, 0), text_scale=4.0):\n",
    "    a = np.array([a.x, a.y, a.z])\n",
    "    b = np.array([b.x, b.y, b.z])\n",
    "    c = np.array([c.x, c.y, c.z])\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    if img_rgb is not None:\n",
    "        height, width, _ = img_rgb.shape\n",
    "\n",
    "        # Scale the coordinates to fit the image dimensions\n",
    "        points = [\n",
    "            (int(a[0] * width), int(a[1] * height)),\n",
    "            (int(b[0] * width), int(b[1] * height)),\n",
    "            (int(c[0] * width), int(c[1] * height))\n",
    "        ]\n",
    "\n",
    "        # Adjust text size based on the image height\n",
    "        text_size = text_scale * height / 1000\n",
    "\n",
    "        cv2.line(img_rgb, points[0], points[1], color, 4)\n",
    "        cv2.line(img_rgb, points[1], points[2], color, 4)\n",
    "        cv2.putText(\n",
    "            img_rgb,\n",
    "            str(int(angle)),\n",
    "            (points[1][0] + 10, points[1][1] - 25),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            text_size,\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "        return angle, img_rgb\n",
    "\n",
    "    return angle, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Push Up Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_pushup(body_parts, vis_threshold=0.75, img_rgb=None):\n",
    "    required_parts = [\n",
    "        'left_shoulder', 'left_elbow', 'left_wrist',\n",
    "        'right_shoulder', 'right_elbow', 'right_wrist',\n",
    "        'left_hip', 'right_hip', 'left_ankle', 'right_ankle'\n",
    "    ]\n",
    "\n",
    "    # Check if any required body part is None\n",
    "    for part in required_parts:\n",
    "        if body_parts[part].visibility == 0:\n",
    "            return -1, img_rgb, None, False\n",
    "\n",
    "    l_sh = body_parts['left_shoulder']\n",
    "    l_elbow = body_parts['left_elbow']\n",
    "    l_wrist = body_parts['left_wrist']\n",
    "    l_hip = body_parts['left_hip']\n",
    "    l_ankle = body_parts['left_ankle']\n",
    "\n",
    "    r_sh = body_parts['right_shoulder']\n",
    "    r_elbow = body_parts['right_elbow']\n",
    "    r_wrist = body_parts['right_wrist']\n",
    "    r_hip = body_parts['right_hip']\n",
    "    r_ankle = body_parts['right_ankle']\n",
    "\n",
    "    # Get visibility of left and right sides\n",
    "    # Left arm and leg\n",
    "    l_vis = (l_wrist.visibility + l_elbow.visibility + l_sh.visibility + l_ankle.visibility + l_hip.visibility) / 5\n",
    "\n",
    "    # Right arm and leg\n",
    "    r_vis = (r_wrist.visibility + r_elbow.visibility + r_sh.visibility + r_ankle.visibility + r_hip.visibility) / 5\n",
    "\n",
    "    # Visibility (assuming 1 arm/ankle will always be obstructed)\n",
    "    if l_vis < vis_threshold and r_vis >= vis_threshold:\n",
    "        t_sh, t_elbow, t_wrist = r_sh, r_elbow, r_wrist\n",
    "        t_hip, t_ankle = r_hip, r_ankle\n",
    "    elif r_vis < vis_threshold and l_vis >= vis_threshold:\n",
    "        t_sh, t_elbow, t_wrist = l_sh, l_elbow, l_wrist\n",
    "        t_hip, t_ankle = l_hip, l_ankle\n",
    "    elif l_vis < vis_threshold and r_vis < vis_threshold:\n",
    "        return -1, img_rgb, None, False\n",
    "    else:\n",
    "        t_sh, t_elbow, t_wrist = l_sh, l_elbow, l_wrist\n",
    "        t_hip, t_ankle = l_hip, l_ankle\n",
    "\n",
    "    # Calculate angles\n",
    "    shoulder_angle, img1 = calculate_angle(t_hip, t_sh, t_elbow, img_rgb, (255, 0, 0))\n",
    "    elbow_angle, img2 = calculate_angle(t_sh, t_elbow, t_wrist, img1, (0, 255, 0))\n",
    "    body_angle, img3 = calculate_angle(t_sh, t_hip, t_ankle, img2, (0, 0, 255))\n",
    "\n",
    "    # Determine movement and correctness\n",
    "    if 0 < shoulder_angle < 80 and 120 < elbow_angle < 180 and 145 < body_angle < 180:\n",
    "        # Correct - extension\n",
    "        movement = 'extension'\n",
    "        correctness = True\n",
    "        return 2, img3, movement, correctness\n",
    "    elif 0 < shoulder_angle < 80 and 50 < elbow_angle < 120 and 145 < body_angle < 180:\n",
    "        # Correct - flexion\n",
    "        movement = 'flexion'\n",
    "        correctness = True\n",
    "        return 1, img3, movement, correctness\n",
    "    else:\n",
    "        # Bad posture\n",
    "        movement = 'other'\n",
    "        correctness = False\n",
    "        return 0, img3, movement, correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def randomly_choose_images_and_process(folder_path, exercise_function, num_images=5):\n",
    "    # Get all files in the specified folder\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out non-image files (optional, depending on your folder content)\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "    image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "    \n",
    "    # Randomly select a specified number of images\n",
    "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
    "\n",
    "    # Process each selected image with the specified exercise function\n",
    "    for img_name in selected_images:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        print(f\"Processing image: {img_path}\")\n",
    "        generic_detector_static(img_path, exercise_function)\n",
    "\n",
    "# Specify the folder containing your images\n",
    "image_folder = r\"cleaned_frames\\train\\push up\"\n",
    "\n",
    "# Number of images to process\n",
    "num_images_to_process = 3\n",
    "\n",
    "# Call the function to randomly choose and process images\n",
    "randomly_choose_images_and_process(image_folder, do_pushup, num_images_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deadlift Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_deadlift(body_parts, vis_threshold=0.75, img_rgb=None):\n",
    "    required_parts = [\n",
    "        'left_shoulder', 'right_shoulder',\n",
    "        'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle',\n",
    "        'left_elbow', 'right_elbow'\n",
    "    ]\n",
    "\n",
    "    # Check if any required body part is None\n",
    "    for part in required_parts:\n",
    "        if body_parts[part].visibility == 0:\n",
    "            return -1, img_rgb, None, False\n",
    "\n",
    "    l_sh = body_parts['left_shoulder']\n",
    "    r_sh = body_parts['right_shoulder']\n",
    "    l_hip = body_parts['left_hip']\n",
    "    r_hip = body_parts['right_hip']\n",
    "    l_knee = body_parts['left_knee']\n",
    "    r_knee = body_parts['right_knee']\n",
    "    l_ankle = body_parts['left_ankle']\n",
    "    r_ankle = body_parts['right_ankle']\n",
    "    l_elbow = body_parts['left_elbow']\n",
    "    r_elbow = body_parts['right_elbow']\n",
    "\n",
    "    # Get visibility of left and right sides\n",
    "    l_vis = (l_sh.visibility + l_hip.visibility + l_knee.visibility + l_ankle.visibility + l_elbow.visibility) / 5\n",
    "    r_vis = (r_sh.visibility + r_hip.visibility + r_knee.visibility + r_ankle.visibility + r_elbow.visibility ) / 5\n",
    "\n",
    "    # Use the side with better visibility\n",
    "    if l_vis < vis_threshold and r_vis >= vis_threshold:\n",
    "        t_sh, t_hip, t_knee, t_ankle, t_elbow  = r_sh, r_hip, r_knee, r_ankle, r_elbow\n",
    "    elif r_vis < vis_threshold and l_vis >= vis_threshold:\n",
    "        t_sh, t_hip, t_knee, t_ankle, t_elbow = l_sh, l_hip, l_knee, l_ankle, l_elbow\n",
    "    elif l_vis < vis_threshold and r_vis < vis_threshold:\n",
    "        return -1, img_rgb, None, False\n",
    "    else:\n",
    "        t_sh, t_hip, t_knee, t_ankle, t_elbow = l_sh, l_hip, l_knee, l_ankle, l_elbow\n",
    "\n",
    "    # Calculate angles correctly\n",
    "    hip_angle, img1 = calculate_angle(t_sh, t_hip, t_knee, img_rgb, (255, 0, 0))\n",
    "    knee_angle, img2 = calculate_angle(t_hip, t_knee, t_ankle, img1, (0, 255, 0))\n",
    "    shoulder_angle, img3 = calculate_angle(t_hip, t_sh, t_elbow, img2, (0, 0, 255))\n",
    "\n",
    "    # Determine movement and correctness\n",
    "    if 110 < hip_angle < 180 and 150 < knee_angle < 180 and 0 < shoulder_angle < 30:\n",
    "        # Correct - extension\n",
    "        movement = 'extension'\n",
    "        correctness = True\n",
    "        return 2, img3, movement, correctness\n",
    "    elif 25 < hip_angle < 110 and 0 < knee_angle < 150 and 0 < shoulder_angle < 90:\n",
    "        # Correct - flexion\n",
    "        movement = 'flexion'\n",
    "        correctness = True\n",
    "        return 1, img3, movement, correctness\n",
    "    else:\n",
    "        # Bad posture \n",
    "        movement = 'other'\n",
    "        correctness = False\n",
    "        return 0, img3, movement, correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Squat Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_squat(body_parts, vis_threshold=0.75, img_rgb=None):\n",
    "    required_parts = [\n",
    "        'left_shoulder', 'right_shoulder',\n",
    "        'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle',\n",
    "    ]\n",
    "\n",
    "    # Check if any required body part is None\n",
    "    for part in required_parts:\n",
    "        if body_parts[part].visibility == 0:\n",
    "            return -1, img_rgb, None, False\n",
    "\n",
    "    l_sh = body_parts['left_shoulder']\n",
    "    r_sh = body_parts['right_shoulder']\n",
    "    l_hip = body_parts['left_hip']\n",
    "    r_hip = body_parts['right_hip']\n",
    "    l_knee = body_parts['left_knee']\n",
    "    r_knee = body_parts['right_knee']\n",
    "    l_ankle = body_parts['left_ankle']\n",
    "    r_ankle = body_parts['right_ankle']\n",
    "\n",
    "    # Get visibility of left and right sides\n",
    "    l_vis = (l_sh.visibility + l_hip.visibility + l_knee.visibility + l_ankle.visibility ) / 4\n",
    "    r_vis = (r_sh.visibility + r_hip.visibility + r_knee.visibility + r_ankle.visibility ) / 4\n",
    "\n",
    "    # Use the side with better visibility\n",
    "    if l_vis < vis_threshold and r_vis >= vis_threshold:\n",
    "        t_sh, t_hip, t_knee, t_ankle = r_sh, r_hip, r_knee, r_ankle\n",
    "    elif r_vis < vis_threshold and l_vis >= vis_threshold:\n",
    "        t_sh, t_hip, t_knee, t_ankle = l_sh, l_hip, l_knee, l_ankle\n",
    "    elif l_vis < vis_threshold and r_vis < vis_threshold:\n",
    "        return -1, img_rgb, None, False\n",
    "    else:\n",
    "        t_sh, t_hip, t_knee, t_ankle = l_sh, l_hip, l_knee, l_ankle\n",
    "\n",
    "    # Calculate angles correctly\n",
    "    hip_angle, img1 = calculate_angle(t_sh, t_hip, t_knee, img_rgb, (255, 0, 0))\n",
    "    knee_angle, img2 = calculate_angle(t_hip, t_knee, t_ankle, img1, (0, 255, 0))\n",
    "\n",
    "    # Calculate the distances between the knees and ankles\n",
    "    knee_distance = np.linalg.norm([l_knee.x - r_knee.x, l_knee.y - r_knee.y, l_knee.z - r_knee.z])\n",
    "    ankle_distance = np.linalg.norm([l_ankle.x - r_ankle.x, l_ankle.y - r_ankle.y, l_ankle.z - r_ankle.z])\n",
    "\n",
    "    # Calculate the ratio and check for knee cave\n",
    "    if knee_distance / ankle_distance < 0.5:  # Example ratio threshold, adjust as needed\n",
    "        #knees caving in\n",
    "        movement = 'other'\n",
    "        correctness = False\n",
    "        return 0, img2, movement, correctness\n",
    "\n",
    "    if 150 < hip_angle < 180 and 150 < knee_angle < 180:\n",
    "        # extended position\n",
    "        movement = 'extension'\n",
    "        correctness = True\n",
    "        return 2, img2, movement, correctness\n",
    "    elif 50 < hip_angle < 160 and 40 < knee_angle < 150:\n",
    "        # flexed position\n",
    "        movement = 'flexion'\n",
    "        correctness = True\n",
    "        return 1, img2, movement, correctness\n",
    "    else:\n",
    "        # bad posture\n",
    "        movement = 'other'\n",
    "        correctness = False\n",
    "        return 0, img2, movement, correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_detector_static(img_path, exercise_function, show_keypoints=False, show_angles=True):\n",
    "    # Mediapipe\n",
    "    mp_detector = mp_init_detector()\n",
    "    mp_img = mp.Image.create_from_file(img_path)\n",
    "    detection_results, body_parts = mp_process_image(\n",
    "        mp_detector,\n",
    "        mp_img\n",
    "    )\n",
    "\n",
    "    # cv2\n",
    "    img_rgb = None\n",
    "    if show_angles:\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Body part usage\n",
    "    if bool(body_parts):\n",
    "        if show_keypoints:\n",
    "            mp_debug_show_image(mp_detector, img_path)\n",
    "\n",
    "        print(\"Exercise Detector\")\n",
    "        result, img_with_angles, _ , _= exercise_function(body_parts, 0.75, img_rgb)\n",
    "        if result < 0:\n",
    "            #might add argument to delete picture?\n",
    "            print(f\"WARNING: Low visibility confidence, skipping {img_path}\")\n",
    "        elif result > 0:\n",
    "            print(\"Good technique\")\n",
    "            if result == 2:\n",
    "                print(\"Extended position\")\n",
    "            elif result == 1:\n",
    "                print(\"Flexed position\")\n",
    "        else:\n",
    "            print(\"Bad technique / different exercise\")\n",
    "\n",
    "        if show_angles and img_with_angles is not None:\n",
    "            cv2_imshow(cv2.cvtColor(img_with_angles, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        print(f\"WARNING: Mediapipe could not detect landmarks, skipping {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushup_detector_static(img_path, show_keypoints=False, show_angles=True):\n",
    "    # Mediapipe\n",
    "    mp_detector = mp_init_detector()\n",
    "    mp_img = mp.Image.create_from_file(img_path)\n",
    "    detection_results, body_parts = mp_process_image(\n",
    "        mp_detector,\n",
    "        mp_img\n",
    "    )\n",
    "\n",
    "    # cv2\n",
    "    img_rgb = None\n",
    "    if show_angles:\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Body part usage\n",
    "    if bool(body_parts):\n",
    "        if show_keypoints:\n",
    "            mp_debug_show_image(mp_detector, img_path)\n",
    "\n",
    "        print(\"Pushup Detector\")\n",
    "        pushup_res, img_with_angles = do_pushup(body_parts, 0.75, img_rgb)\n",
    "        if pushup_res < 0:\n",
    "            print(f\"WARNING: Low visibility confidence, skipping {img_path}\")\n",
    "        elif pushup_res > 0:\n",
    "            print(\"Good posture\")\n",
    "            if pushup_res == 2:\n",
    "                print(\"Raised pushup\")\n",
    "            elif pushup_res == 1:\n",
    "                print(\"Lowered pushup\")\n",
    "        else:\n",
    "            print(\"Bad posture\")\n",
    "\n",
    "        if show_angles and img_with_angles is not None:\n",
    "            cv2_imshow(cv2.cvtColor(img_with_angles, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        print(f\"WARNING: Mediapipe could not detect landmarks, skipping {img_path}\")\n",
    "\n",
    "\n",
    "def pushup_detector_dynamic(frame, detector, show_keypoints=False, show_angles=True):\n",
    "    mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    detection_results, body_parts = mp_process_image(detector, mp_img)\n",
    "\n",
    "    img_rgb = None\n",
    "    if show_angles:\n",
    "        img_rgb = frame\n",
    "\n",
    "    if bool(body_parts):\n",
    "        # Draw full body landmarks\n",
    "        if show_keypoints:\n",
    "            res_frame = draw_landmarks_on_image(img_rgb, detection_results)\n",
    "            return res_frame, None\n",
    "\n",
    "        #result, img_with_angles, movement, correctness\n",
    "        pushup_res, res_frame, _, _ = do_pushup(body_parts, 0.75, img_rgb)\n",
    "\n",
    "        if pushup_res > 0:\n",
    "            print(\"Good posture\")\n",
    "            if pushup_res == 2:\n",
    "                return res_frame, \"Raised pushup\"\n",
    "            elif pushup_res == 1:\n",
    "                return res_frame, \"Lowered pushup\"\n",
    "        else:\n",
    "            return res_frame, \"Bad posture\"\n",
    "\n",
    "    # If no body parts detected or any other condition, return the frame with a default message\n",
    "    return frame, \"No body parts detected\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def annotate_images(source_dirs, output_csv, detector):\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"image_path\", \"exercise\", \"keypoints\", \"movement\", \"correctness\"])\n",
    "        \n",
    "        for exercise, source_dir in source_dirs.items():\n",
    "            for img_name in os.listdir(source_dir):\n",
    "                img_path = os.path.join(source_dir, img_name)\n",
    "                mp_image = mp.Image.create_from_file(img_path)\n",
    "                detection_result, body_parts = mp_process_image(detector, mp_image)\n",
    "                \n",
    "                if not body_parts:\n",
    "                    continue\n",
    "\n",
    "                if exercise == \"pushup\":\n",
    "                    result, img_with_angles, movement, correctness = do_pushup(body_parts, 0.75)\n",
    "                elif exercise == \"squat\":\n",
    "                    result, img_with_angles, movement, correctness = do_squat(body_parts, 0.75)\n",
    "                elif exercise == \"deadlift\":\n",
    "                    result, img_with_angles, movement, correctness = do_deadlift(body_parts, 0.75)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                if result < 0:\n",
    "                    continue\n",
    "\n",
    "                keypoints = {k: [v.x, v.y, v.z, v.visibility] for k, v in body_parts.items()}\n",
    "\n",
    "                writer.writerow([img_path, exercise, json.dumps(keypoints), movement, correctness])\n",
    "\n",
    "# Define source directories and output CSV\n",
    "source_dirs = {\n",
    "    \"pushup\": r\"cleaned_frames\\val\\push up\",\n",
    "    \"squat\": r\"cleaned_frames\\val\\squat\",\n",
    "    \"deadlift\": r\"cleaned_frames\\val\\deadlifting\"\n",
    "}\n",
    "output_csv = \"annotations_val.csv\"\n",
    "\n",
    "# Annotate images\n",
    "mp_detector = mp_init_detector()\n",
    "annotate_images(source_dirs, output_csv, mp_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Webcam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam():\n",
    "    detector = mp_init_detector()\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            continue\n",
    "\n",
    "        #result, img_with_angles, movement, correctness\n",
    "        frame, guide= pushup_detector_dynamic(frame, detector, show_keypoints=False, show_angles=True)\n",
    "\n",
    "        # Display the classification and guide on the top right of the frame\n",
    "        text_x = frame.shape[1] - 300  # Adjust x position based on frame width\n",
    "        classification = \"Pushup\"\n",
    "        cv2.putText(frame, classification, (text_x, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "        if guide:\n",
    "            cv2.putText(frame, guide, (text_x, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Pushup Detector', frame)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# NOTE: Hold q to close the webcam\n",
    "run_webcam()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
